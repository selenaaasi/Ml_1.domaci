{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def split_test_train(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "def standard_scaler(X_train,X_test):\n",
    "    sc_X = StandardScaler()\n",
    "    X_train_scale = sc_X.fit_transform(X_train)\n",
    "    X_test_scale = sc_X.transform(X_test)\n",
    "    return X_train_scale,X_test_scale\n",
    "\n",
    "#Univariate Selection - 2,3,4,5\n",
    "def univariate_selection(X_train,y_train):\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=5)\n",
    "    fit = bestfeatures.fit(X_train, y_train)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X_train.columns)\n",
    "    # concat two dataframes for better visualization\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Specs', 'Score']  # naming the dataframe columns\n",
    "    print(featureScores.nlargest(4, 'Score'))\n",
    "\n",
    "#RFE-2,5,6,15\n",
    "def RFE_col(X_train,y_train):\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    rfe = RFE(classifier, 4)\n",
    "    fit = rfe.fit(X_train, y_train)\n",
    "    print(\"Num Features: %d\" % fit.n_features_)\n",
    "    print(\"Selected Features: %s\" % fit.support_)\n",
    "    print(\"Feature Ranking: %s\" % fit.ranking_)\n",
    "    rfe_rank = fit.ranking_\n",
    "\n",
    "#PCA 4,11,9,17\n",
    "def PCA_col(X_train,y_train):\n",
    "    pca_example=PCA().fit(X_train)\n",
    "    print(\"Explained_variance_ratio\")\n",
    "    print(pca_example.explained_variance_ratio_)\n",
    "    pca = PCA(n_components=4).fit(X_train)\n",
    "    n_pcs = pca.components_.shape[0]\n",
    "    most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "    initial_feature_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16',\n",
    "                             '17']\n",
    "    most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "    # using LIST COMPREHENSION HERE AGAIN\n",
    "    dic = {'PC{}'.format(i + 1): most_important_names[i] for i in range(n_pcs)}\n",
    "    # build the dataframe\n",
    "    df = pd.DataFrame(sorted(dic.items()))\n",
    "    print(df)\n",
    "\n",
    "#Decision Tree-2,3,8,4\n",
    "def decision_tree(X_train,y_train):\n",
    "    model = ExtraTreesClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.feature_importances_)  # use inbuilt class feature_importances of tree based classifiers\n",
    "    # plot graph of feature importances for better visualization\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    feat_importances.nlargest(10).plot(kind='barh')\n",
    "    print(\"Feature importance\")\n",
    "    print(feat_importances)\n",
    "    plt.show()\n",
    "\n",
    "#Logistic regression\n",
    "def logistic_regression(X_train,y_train,X_test,y_test):\n",
    "    classifier = LogisticRegression(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = cross_val_score(classifier, X_test, y_test, cv=10)\n",
    "    print(\"SCORE:\")\n",
    "    print(score)\n",
    "    print(\"Average score:\")\n",
    "    print(statistics.mean(score))\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    #plt.rcParams['font.size'] = 12\n",
    "    #plt.hist(score, bins=8)\n",
    "\n",
    "    # x-axis limit from 0 to 1\n",
    "    #plt.xlim(0, 1)\n",
    "    #plt.title('Histogram of predicted probabilities')\n",
    "    #plt.xlabel('Predicted probability of diabetes')\n",
    "    #plt.ylabel('Frequency')\n",
    "    #plt.show()\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "#Process data\n",
    "def process_data(X,y):\n",
    "    X_train, X_test, y_train, y_test = split_test_train(X, y)\n",
    "    X_train_scale, X_test_scale = standard_scaler(X_train, X_test)\n",
    "    logistic_regression(X_train_scale, y_train, X_test_scale, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = pd.read_csv(\"csv_result-diabetic_dataset.csv\")\n",
    "\n",
    "    # all col\n",
    "    X = dataset.iloc[:, 1:19]\n",
    "    y = dataset.iloc[:, 20]\n",
    "    # random\n",
    "    array = random.sample(range(0, 17), 4)\n",
    "    X_random = dataset.iloc[:, [array[0], array[1], array[2],array[3]]]\n",
    "    y_random = dataset.iloc[:, 20]\n",
    "\n",
    "    # Univariate Selection\n",
    "    X_unvariate_selection = dataset.iloc[:, [2, 3, 4, 5]]\n",
    "    y_unvariate_selection = dataset.iloc[:, 20]\n",
    "\n",
    "    # RFE\n",
    "    X_rfe = dataset.iloc[:, [2,5, 6, 15]]\n",
    "    y_rfe = dataset.iloc[:, 20]\n",
    "\n",
    "    # PCA\n",
    "    X_PCA = dataset.iloc[:, [4,9,11, 17]]\n",
    "    y_PCA = dataset.iloc[:, 20]\n",
    "\n",
    "    # DecisionTree\n",
    "    X_dt = dataset.iloc[:, [2, 3, 4, 8]]\n",
    "    y_dt = dataset.iloc[:, 20]\n",
    "\n",
    "    X_train, X_test, y_train, y_test=split_test_train(X,y)\n",
    "    univariate_selection(X_train, y_train)\n",
    "    X_train_scale,X_test_scale=standard_scaler(X_train,X_test)\n",
    "    RFE_col(X_train_scale,y_train)\n",
    "    PCA_col(X_train_scale,y_train)\n",
    "    decision_tree(X_train_scale,y_train)\n",
    "\n",
    "    print(\"Sve kolone>>>>>>>>>\")\n",
    "    logistic_regression(X_train_scale,y_train,X_test_scale,y_test)\n",
    "    print(\"Nasumicno izabranih 5 kolona>>>>>>\")\n",
    "    process_data(X_random,y_random)\n",
    "    print(\"Univariate Selection>>>>>>\")\n",
    "    process_data(X_unvariate_selection, y_unvariate_selection)\n",
    "    print(\"RFE>>>>>>\")\n",
    "    process_data(X_rfe,y_rfe)\n",
    "    print(\"PCA>>>>>>\")\n",
    "    process_data(X_PCA,y_PCA)\n",
    "    print(\"Decision tree>>>>>\")\n",
    "    process_data(X_dt,y_dt)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
